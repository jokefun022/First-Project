{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMP0hL1Bxq0ca6Uh6KzpYvJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jokefun022/First-Project/blob/main/Emoji.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install emoji library if not already available\n",
        "!pip install -q emoji pandas\n",
        "\n",
        "import pandas as pd\n",
        "import emoji\n",
        "import re\n",
        "\n",
        "# # === Step 1: Load your dataset ===\n",
        "# # If the file is on Google Drive, mount and set the correct path\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Change this path to match your Drive file location\n",
        "path = \"/content/Complete Data With Emoji.csv\"\n",
        "\n",
        "df = pd.read_csv(path, encoding='utf-8')\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# Detect likely text column (if it's Tweet_Text_With_Emoji as before)\n",
        "text_col = None\n",
        "for c in df.columns:\n",
        "    if 'text' in c.lower() or 'tweet' in c.lower() or 'comment' in c.lower():\n",
        "        text_col = c\n",
        "        break\n",
        "if text_col is None:\n",
        "    text_col = df.columns[0]  # fallback to first column\n",
        "print(\"Using text column:\", text_col)\n",
        "\n",
        "# === Step 2: Extract emojis from text ===\n",
        "def extract_emojis(text):\n",
        "    return ''.join(ch for ch in str(text) if ch in emoji.EMOJI_DATA)\n",
        "\n",
        "df['emojis'] = df[text_col].apply(extract_emojis)\n",
        "\n",
        "# === Step 3: Get all emojis in dataset at one place ===\n",
        "all_emojis = ''.join(df['emojis'].tolist())\n",
        "unique_emojis = sorted(set(all_emojis))\n",
        "\n",
        "print(\"Total emojis found:\", len(all_emojis))\n",
        "print(\"Unique emojis found:\", len(unique_emojis))\n",
        "print(\"All unique emojis:\\n\", ' '.join(unique_emojis))\n",
        "\n",
        "# === Step 4 (Optional): Frequency of each emoji ===\n",
        "from collections import Counter\n",
        "emoji_counts = Counter(all_emojis)\n",
        "print(\"\\nTop 20 emojis by frequency:\")\n",
        "for e, count in emoji_counts.most_common(20):\n",
        "    print(e, count)\n"
      ],
      "metadata": {
        "id": "kFWLpw1Ho5Ux",
        "outputId": "d56e39b4-cf9c-48ea-92fb-84aa776597ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (10672, 3)\n",
            "Columns: ['Tweet_Text_With_Emoji', 'Label', 'Sentiment Analysis']\n",
            "Using text column: Tweet_Text_With_Emoji\n",
            "Total emojis found: 10734\n",
            "Unique emojis found: 119\n",
            "All unique emojis:\n",
            " ↔ ☠ ☹ ☺ ⚔ ⚡ ⚧ 🌈 👊 👍 👎 👧 👩 👭 👹 👺 👽 👿 💀 💔 💣 💩 💫 🔥 🖕 🖤 😀 😂 😃 😄 😅 😆 😇 😈 😉 😊 😋 😌 😍 😎 😏 😐 😑 😒 😓 😔 😕 😖 😗 😘 😙 😚 😛 😜 😝 😞 😟 😠 😡 😣 😤 😦 😧 😨 😩 😫 😬 😭 😮 😯 😱 😲 😳 😵 😶 😹 😼 😾 🙀 🙁 🙂 🙃 🙄 🙌 🤐 🤒 🤓 🤔 🤕 🤗 🤝 🤞 🤡 🤢 🤣 🤥 🤧 🤨 🤪 🤫 🤬 🤭 🤮 🤯 🥰 🥲 🥴 🥵 🥸 🥺 🧐 🧟 🫠 🫡 🫢 🫣 🫤 🫥 🫨\n",
            "\n",
            "Top 20 emojis by frequency:\n",
            "🙂 659\n",
            "😄 650\n",
            "😃 630\n",
            "😊 618\n",
            "😌 617\n",
            "😎 613\n",
            "👍 598\n",
            "🤝 586\n",
            "🙌 561\n",
            "🤗 561\n",
            "😒 355\n",
            "😠 181\n",
            "🧟 143\n",
            "😆 133\n",
            "😤 132\n",
            "😑 102\n",
            "🤬 100\n",
            "🙄 89\n",
            "👿 82\n",
            "😡 78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q emoji pandas\n",
        "\n",
        "import pandas as pd\n",
        "import emoji\n",
        "\n",
        "# # === Step 1: Load your dataset ===\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Change this path if needed\n",
        "path = \"/content/Complete Data With Emoji.csv\"\n",
        "\n",
        "df = pd.read_csv(path, encoding=\"utf-8\")\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# Detect likely text column\n",
        "text_col = None\n",
        "for c in df.columns:\n",
        "    if \"text\" in c.lower() or \"tweet\" in c.lower() or \"comment\" in c.lower():\n",
        "        text_col = c\n",
        "        break\n",
        "if text_col is None:\n",
        "    text_col = df.columns[0]  # fallback\n",
        "print(\"Using text column:\", text_col)\n",
        "\n",
        "# === Step 2: Extract emojis ===\n",
        "def extract_emojis(text):\n",
        "    return ''.join(ch for ch in str(text) if ch in emoji.EMOJI_DATA)\n",
        "\n",
        "df[\"emojis\"] = df[text_col].apply(extract_emojis)\n",
        "\n",
        "# === Step 3: Collect all emojis across dataset ===\n",
        "all_emojis = ''.join(df[\"emojis\"].tolist())\n",
        "unique_emojis = sorted(set(all_emojis))\n",
        "\n",
        "print(f\"\\n✅ Found {len(unique_emojis)} unique emojis in the dataset.\\n\")\n",
        "print(\"All emojis used:\\n\")\n",
        "print(' '.join(unique_emojis))\n",
        "\n",
        "# === Step 4: (Optional) Save to file for download ===\n",
        "with open(\"unique_emojis.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(' '.join(unique_emojis))\n",
        "\n",
        "print(\"\\nUnique emojis saved to unique_emojis.txt (you can download from Colab).\")\n"
      ],
      "metadata": {
        "id": "kJztJIMFp-AW",
        "outputId": "4b2903a4-20a3-4c8e-ee7b-f8516a6439c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (10672, 3)\n",
            "Columns: ['Tweet_Text_With_Emoji', 'Label', 'Sentiment Analysis']\n",
            "Using text column: Tweet_Text_With_Emoji\n",
            "\n",
            "✅ Found 119 unique emojis in the dataset.\n",
            "\n",
            "All emojis used:\n",
            "\n",
            "↔ ☠ ☹ ☺ ⚔ ⚡ ⚧ 🌈 👊 👍 👎 👧 👩 👭 👹 👺 👽 👿 💀 💔 💣 💩 💫 🔥 🖕 🖤 😀 😂 😃 😄 😅 😆 😇 😈 😉 😊 😋 😌 😍 😎 😏 😐 😑 😒 😓 😔 😕 😖 😗 😘 😙 😚 😛 😜 😝 😞 😟 😠 😡 😣 😤 😦 😧 😨 😩 😫 😬 😭 😮 😯 😱 😲 😳 😵 😶 😹 😼 😾 🙀 🙁 🙂 🙃 🙄 🙌 🤐 🤒 🤓 🤔 🤕 🤗 🤝 🤞 🤡 🤢 🤣 🤥 🤧 🤨 🤪 🤫 🤬 🤭 🤮 🤯 🥰 🥲 🥴 🥵 🥸 🥺 🧐 🧟 🫠 🫡 🫢 🫣 🫤 🫥 🫨\n",
            "\n",
            "Unique emojis saved to unique_emojis.txt (you can download from Colab).\n"
          ]
        }
      ]
    }
  ]
}