{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNPQ0x9gTiKZgpZD71mBQa+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jokefun022/jokefun022/blob/main/21_08_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "555f66a2",
        "outputId": "1c4c603f-871f-496a-eccf-fa670b88a073"
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aee92dd",
        "outputId": "36a92ed4-daa7-47f9-af1f-6075c1a1e2a3"
      },
      "source": [
        "# Load the dataset again to inspect columns\n",
        "tweets_check = pd.read_csv(\"/content/Complete Data With Emoji.csv\")\n",
        "\n",
        "# Print the column names\n",
        "print(tweets_check.columns)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Tweet_Text_With_Emoji', 'Label', 'Sentiment Analysis'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb9df606",
        "outputId": "c3335f23-4c09-4793-b748-406c36b8b9d7"
      },
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score,precision_score, recall_score, f1_score, confusion_matrix\n",
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load the dataset\n",
        "tweets = pd.read_csv(\"/content/Complete Data With Emoji.csv\",usecols=['Tweet_Text_With_Emoji', 'Label'])\n",
        "\n",
        "# Preprocess the tweets (optional)\n",
        "def preprocess_text(text):\n",
        "    # Apply any text preprocessing steps you want, like lowercasing, stemming, etc.\n",
        "    return text.lower()\n",
        "\n",
        "preprocessed_tweets = [preprocess_text(tweet) for tweet in tweets['Tweet_Text_With_Emoji']]\n",
        "y =tweets['Label']\n",
        "\n",
        "\n",
        "# Vectorize the text data using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(preprocessed_tweets)\n",
        "\n",
        "# Initialize the KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize the Naive Bayes classifier\n",
        "clf = MultinomialNB()\n",
        "\n",
        "# Perform cross-validation\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "for train_index, test_index in kf.split(X_tfidf):\n",
        "    X_train, X_test = X_tfidf[train_index], X_tfidf[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the Naive Bayes classifier\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision= precision_score(y_test, y_pred,average='weighted')\n",
        "    precision_scores.append(precision)\n",
        "    recall= recall_score(y_test, y_pred,average='weighted')\n",
        "    recall_scores.append(recall)\n",
        "    f1 = f1_score(y_test, y_pred,average='weighted')\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "# Calculate the average accuracy score\n",
        "avg_accuracy = np.mean(accuracy_scores)\n",
        "print(\"Average accuracy: \", avg_accuracy)\n",
        "avg_precision = np.mean(precision_scores)\n",
        "print(\"Average precision: \", avg_precision)\n",
        "avg_recall = np.mean(recall_scores)\n",
        "print(\"Average recall: \", avg_recall)\n",
        "avg_f1 = np.mean(f1_scores)\n",
        "print(\"Average f1-measure: \", avg_f1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.99      0.85      1234\n",
            "           1       1.00      0.06      0.12       139\n",
            "           2       0.81      0.66      0.73       611\n",
            "           3       1.00      0.03      0.05        75\n",
            "           4       1.00      0.07      0.12        76\n",
            "\n",
            "    accuracy                           0.77      2135\n",
            "   macro avg       0.91      0.36      0.38      2135\n",
            "weighted avg       0.80      0.77      0.71      2135\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.99      0.85      1238\n",
            "           1       0.92      0.08      0.15       147\n",
            "           2       0.83      0.65      0.72       612\n",
            "           3       1.00      0.01      0.03        69\n",
            "           4       1.00      0.07      0.14        69\n",
            "\n",
            "    accuracy                           0.77      2135\n",
            "   macro avg       0.90      0.36      0.38      2135\n",
            "weighted avg       0.80      0.77      0.72      2135\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83      1171\n",
            "           1       0.94      0.10      0.18       154\n",
            "           2       0.83      0.59      0.69       654\n",
            "           3       1.00      0.03      0.07        87\n",
            "           4       1.00      0.04      0.08        68\n",
            "\n",
            "    accuracy                           0.74      2134\n",
            "   macro avg       0.90      0.35      0.37      2134\n",
            "weighted avg       0.78      0.74      0.68      2134\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      1.00      0.85      1217\n",
            "           1       1.00      0.09      0.17       143\n",
            "           2       0.84      0.67      0.75       619\n",
            "           3       1.00      0.02      0.05        84\n",
            "           4       1.00      0.11      0.20        71\n",
            "\n",
            "    accuracy                           0.77      2134\n",
            "   macro avg       0.92      0.38      0.40      2134\n",
            "weighted avg       0.81      0.77      0.72      2134\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      1.00      0.84      1195\n",
            "           1       0.81      0.09      0.16       142\n",
            "           2       0.85      0.62      0.72       645\n",
            "           3       0.00      0.00      0.00        83\n",
            "           4       1.00      0.03      0.06        69\n",
            "\n",
            "    accuracy                           0.76      2134\n",
            "   macro avg       0.68      0.35      0.36      2134\n",
            "weighted avg       0.75      0.76      0.70      2134\n",
            "\n",
            "Average accuracy:  0.7602122872901983\n",
            "Average precision:  0.7894208099840279\n",
            "Average recall:  0.7602122872901983\n",
            "Average f1-measure:  0.7086644935348133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}